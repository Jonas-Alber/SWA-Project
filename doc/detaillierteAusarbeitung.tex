\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{url}
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{caption}

% --- ERWEITERTE TIKZ-BIBLIOTHEKEN FÜR BESSERE SCHAUBILDER ---
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning, fit, backgrounds, shapes.symbols}

% --- HYPERREF MUSS MEIST ZULETZT GELADEN WERDEN ---
\usepackage{hyperref}
\hypersetup{
colorlinks=true,
linkcolor=blue,
filecolor=magenta,
urlcolor=cyan,
pdftitle={Ausarbeitung zum Pipeline-Architekturstil},
pdfauthor={Alber Jonas, Schweitzer Tim},
pdfsubject={Softwarearchitektur},
pdfkeywords={Pipeline, Pipes and Filters, Architekturstil, Software Engineering},
bookmarks=true,
pdfpagemode=FullScreen,
}

% ---  TIKZ-STILE FÜR BESSERE LESBARKEIT ---
\tikzstyle{filter_node} = [rectangle, rounded corners, minimum height=1.2cm, text centered, draw=black, fill=blue!20, font=\small]
\tikzstyle{source_sink} = [ellipse, minimum height=1.2cm, text centered, draw=black, fill=red!20, font=\small]
\tikzstyle{tester_node} = [diamond, aspect=1.5, minimum height=1.2cm, text centered, draw=black, fill=orange!30, font=\small, inner xsep=0]
\tikzstyle{broker_node} = [cylinder, shape border rotate=90, aspect=0.5, minimum height=1.5cm, text centered, draw=black, fill=yellow!40, font=\small]
\tikzstyle{pipe_arrow} = [thick, -{Stealth[length=3mm, width=2mm]}]
\tikzstyle{pipe_label} = [font=\footnotesize, fill=white, inner sep=1pt]

\title{Ausarbeitung zum Pipeline-Architekturstil}
\author{Alber Jonas (Matrikelnummer), Schweitzer Tim 29844429}
\date{\today}
\begin{document}

\maketitle

\begin{abstract}
\noindent % Verhindert Einzug
Der Pipeline-Architekturstil (Pipes-and-Filters) ist ein etabliertes Paradigma zur Strukturierung von Systemen in modulare, sequenzielle Verarbeitungsschritte. Aufgrund seiner konzeptionellen Einfachheit und Modularität eignet er sich besonders für datenflussorientierte Aufgaben.\cite{richards2020} Diese Ausarbeitung analysiert die Kernprinzipien dieses Stils, beleuchtet typische Anwendungsfelder und bewertet kritisch dessen Vor- und Nachteile. Ein besonderer Fokus liegt auf der Evolution von traditionellen, monolithischen Implementierungen hin zu modernen, verteilten Streaming-Paradigmen und den damit verbundenen neuen Herausforderungen. Die Untersuchung unterstreicht die anhaltende Relevanz des Musters für die Bewältigung komplexer Datenverarbeitungsaufgaben.
\end{abstract}

\section{Einführung und Historischer Kontext}
Der Pipeline-Architekturstil, auch als Pipes-and-Filters bekannt, zerlegt komplexe Funktionalität in eine Kette unabhängiger, sequenzieller Verarbeitungsschritte. Die Klarheit des Datenflusses macht ihn zu einer attraktiven Wahl für viele Probleme, insbesondere in der Datenverarbeitung. Trotz neuerer Architekturparadigmen hat der Stil seine Relevanz bewahrt und erlebt durch moderne Technologien eine Renaissance.

Die philosophische Grundlage ist das Prinzip "Teile und Herrsche". Anstatt ein Problem monolithisch zu lösen, wird es in kleinere, handhabbare Teilprobleme zerlegt, die von spezialisierten Komponenten – den Filtern – gelöst werden. Diese Vorgehensweise reduziert die kognitive Komplexität und fördert die Modularität und Wartbarkeit des Systems.\cite{richards2020}

Der Erfolg des Musters wird eindrücklich durch die Unix-Philosophie illustriert. Die Möglichkeit, einfache Kommandozeilenwerkzeuge (Filter) über das Pipe-Symbol (|) zu mächtigen Verarbeitungsketten zu verbinden, demonstriert die Kernstärke des Ansatzes.\cite{richards2020, uqcloud_pipeline} Die bekannte Anekdote, die ein komplexes Pascal-Programm von Donald Knuth zur Worthäufigkeitsanalyse einem prägnanten Unix-Shell-Skript von Doug McIlroy gegenüberstellt, verdeutlicht ein fundamentales Prinzip: Die Komposition einfacher, wiederverwendbarer Komponenten führt oft zu eleganteren und verständlicheren Lösungen als ein monolithischer Ansatz.\cite{richards2020}

\section{Kernarchitektur: Filter, Pipes und Designprinzipien}
Die Pipeline-Architektur basiert auf zwei fundamentalen Komponenten: \textbf{Filtern} als autonome Verarbeitungseinheiten und \textbf{Pipes} als unidirektionale Kommunikationskanäle, die den Datenfluss steuern.\cite{richards2020, oreilly_python_pipes}

\subsection{Filter: Die Verarbeitungseinheiten}
Filter sind die aktiven Komponenten, die Daten transformieren. Ihre Effektivität hängt von mehreren Kerneigenschaften ab:

\begin{itemize}
\item \textbf{Unabhängigkeit:} Filter operieren autonom und kennen ihre Nachbarn nicht. Sie kommunizieren nur über Pipes. Dies ermöglicht den Austausch oder die Änderung eines Filters, ohne andere Teile des Systems zu beeinflussen, solange der Datenvertrag der Pipe eingehalten wird.\cite{richards2020}
\item \textbf{Zustandslosigkeit (Statelessness):} Idealerweise hängt die Ausgabe eines Filters nur von der aktuellen Eingabe ab. Diese Eigenschaft ist die fundamentalste Voraussetzung für horizontale Skalierbarkeit und Robustheit, da Anfragen einfach auf mehrere Instanzen verteilt oder im Fehlerfall wiederholt werden können. Ist Zustand unvermeidbar (z.B. bei der Aggregation von Daten über Zeitfenster), muss dieser extern verwaltet werden (etwa in einer Datenbank oder einem verteilten Cache wie Redis), um den Filter selbst zustandslos zu halten. Dies führt jedoch neue Abhängigkeiten und potenzielle Engpässe durch Latenz und Konsistenzmanagement ein.\cite{researchgate_parallel_pipes}
\item \textbf{Einzige Verantwortlichkeit (Single Responsibility):} Jeder Filter erfüllt genau eine klar definierte Aufgabe. Komplexe Logik wird auf mehrere spezialisierte Filter aufgeteilt, was die Wiederverwendbarkeit, Testbarkeit und Verständlichkeit erhöht.\cite{richards2020}
\end{itemize}

Es gibt vier primäre \textbf{Filtertypen}:\cite{uqcloud_pipeline, richards2020}
\begin{itemize}
\item \textbf{Producer (Quelle):} Initiiert den Datenfluss (z.B. aus einer Datei oder Datenbank) und hat keinen Eingang.
\item \textbf{Transformer (Umwandler):} Empfängt Daten, modifiziert sie (z.B. Konvertierung, Anreicherung) und leitet sie weiter.
\item \textbf{Tester (Filter i.e.S.):} Bewertet Daten anhand von Kriterien und leitet sie weiter, verwirft sie oder routet sie bedingt.
\item \textbf{Consumer (Senke):} Bildet den Endpunkt der Pipeline (z.B. Speichern in einer Datenbank) und hat keinen Ausgang.
\end{itemize}

% --- SCHAUBILD 1: KERNARCHITEKTUR MIT DATENTRANSFORMATION ---
\begin{figure}[h!]
\centering
\begin{tikzpicture}[node distance=1cm and 2.2cm, auto]
\node (producer) [source_sink, text width=1.8cm] {Producer (Quelle)};
\node (transformer) [filter_node, text width=1.8cm, right=of producer] {Transformer};
\node (tester) [tester_node, text width=1.5cm, right=of transformer] {Tester};
\node (consumer) [source_sink, text width=1.8cm, right=of tester] {Consumer (Senke)};

% Pfeile mit beschreibenden Labels, um die Transformation zu visualisieren
\draw [pipe_arrow] (producer) -- node[pipe_label] {Rohdaten} (transformer);
\draw [pipe_arrow] (transformer) -- node[pipe_label] {Transformierte Daten} (tester);
\draw [pipe_arrow] (tester) -- node[pipe_label] {Gefilterte Daten} (consumer);
\end{tikzpicture}
\caption{Grundlegende Struktur einer Pipeline-Architektur. Daten durchlaufen verschiedene Zustände, während sie von einer Quelle (Producer) durch verarbeitende Filter (Transformer, Tester) zu einer Senke (Consumer) fließen.}
\label{fig:core_architecture}
\end{figure}

\subsection{Pipes: Die Kommunikations- und Kopplungselemente}
Pipes sind mehr als nur passive Kanäle; sie sind gerichtete, unidirektionale Kopplungspunkte, die Filter verbinden und entkoppeln.\cite{oreilly_python_pipes} Sie ermöglichen asynchrone Verarbeitung und puffern Daten zwischen Filtern, die mit unterschiedlichen Geschwindigkeiten arbeiten.

Die \textit{Implementierung} von Pipes variiert stark: von In-Memory-Queues in Monolithen bis zu robusten Message Brokern (z.B. Apache Kafka, RabbitMQ) in verteilten Systemen. Letztere bieten zusätzliche Garantien wie Persistenz und Lastverteilung.\cite{richards2020} Entscheidender als das \textit{Payload-Format} (z.B. JSON, XML) ist der \textbf{Datenvertrag} – die genaue Struktur und Semantik der Daten. Dieser stellt trotz der Entkopplung eine starke, aber oft implizite, logische Abhängigkeit dar und ist eine der Hauptfehlerquellen in solchen Systemen. Änderungen am Vertrag (Schema-Evolution) erfordern oft Anpassungen in allen nachfolgenden Filtern. Um diese "Vertragsbrüche" zu managen, setzen moderne Systeme auf explizite Mechanismen wie \textit{Schema-Registries} (z.B. Confluent Schema Registry), die die Kompatibilität von Datenformaten versionieren und erzwingen können.

\subsection{Zentrale Designprinzipien}
\begin{itemize}
\item \textbf{Komposition:} Komplexe Verarbeitungsketten werden durch das Zusammensetzen einfacher, fokussierter Filter erstellt. Dies erlaubt eine iterative Entwicklung und Modifikation des Systems.\cite{richards2020}
\item \textbf{Modularität und Wiederverwendbarkeit:} Unabhängige Filter mit klaren Schnittstellen können in verschiedenen Pipelines wiederverwendet werden, was Entwicklungszeit spart.
\item \textbf{Unidirektionaler Datenfluss:} Der lineare Datenfluss vereinfacht das Verständnis und die Fehleranalyse. Er limitiert jedoch die Eignung für interaktive Systeme, die bidirektionale Kommunikation erfordern.\cite{richards2020, uqcloud_pipeline}
\end{itemize}

\section{Anwendungsfelder des Pipeline-Stils}
Der Stil eignet sich besonders für Aufgaben, die eine sequenzielle Datentransformation erfordern.\cite{richards2020}
\begin{itemize}
\item \textbf{ETL-Prozesse (Extrahieren, Transformieren, Laden):} Ein klassisches Anwendungsfeld. Ein Producer-Filter extrahiert Daten, Transformer- und Tester-Filter bereinigen, aggregieren und formatieren sie, und ein Consumer-Filter lädt sie in ein Zielsystem wie ein Data Warehouse.\cite{projectpro_etl_usecases}
\item \textbf{Compilerbau:} Der Quellcode durchläuft sequenziell Phasen wie lexikalische und syntaktische Analyse, Optimierung und Zielcode-Generierung, die jeweils als Filter modelliert werden können.\cite{richards2020}
\item \textbf{Streaming-Datenverarbeitung:} Moderne Frameworks (z.B. Apache Flink, Kafka Streams) nutzen das Pipeline-Paradigma für die Echtzeitanalyse von Sensordaten, Klickströmen oder Finanztransaktionen. Apache Kafka dient dabei oft als hochperformante, skalierbare Pipe-Infrastruktur.\cite{acceldata_streaming}
\item \textbf{Electronic Data Interchange (EDI):} Pipelines konvertieren und validieren Geschäftsdatenaustauschformate, wobei Filter Aufgaben wie Parsen, Schema-Validierung und Feld-Mapping übernehmen.\cite{richards2020}
\end{itemize}

% --- SCHAUBILD 2: ANWENDUNGSBEISPIEL ETL MIT KLAREM FLUSS ---
\begin{figure}[h!]
\centering
\begin{tikzpicture}[node distance=1.2cm and 1.5cm, auto]
\node (source) [source_sink, text width=2.5cm] {Datenquellen (DB, API, Files)};
\node (extract) [filter_node, text width=2cm, below=of source] {Extract (Producer)};
\node (clean) [filter_node, text width=2cm, right=of extract] {Daten bereinigen (Transformer)};
\node (enrich) [filter_node, text width=2cm, right=of clean] {Daten anreichern (Transformer)};
\node (load) [filter_node, text width=2cm, right=of enrich] {Laden (Consumer)};
\node (target) [source_sink, text width=2.5cm, below=of load] {Data Warehouse};

% Pfeile mit beschreibenden Labels für den Datenzustand
\draw [pipe_arrow] (source) -- (extract);
\draw [pipe_arrow] (extract) -- node[pipe_label] {Rohdaten} (clean);
\draw [pipe_arrow] (clean) -- node[pipe_label] {Gesäubert} (enrich);
\draw [pipe_arrow] (enrich) -- node[pipe_label] {Angereichert} (load);
\draw [pipe_arrow] (load) -- (target);
\end{tikzpicture}
\caption{Anwendungsbeispiel einer Pipeline für einen ETL-Prozess (Extract, Transform, Load). Der Datenfluss ist klar von der Quelle über die Transformationsschritte zur Senke visualisiert.}
\label{fig:etl_example}
\end{figure}

\section{Kritische Bewertung und Kompromisse}
\subsection{Vorteile: Analyse und Begründung}
Die Hauptvorteile des Pipeline-Stils sind analytisch begründbar:
\begin{itemize}
\item \textbf{Einfachheit der Anwendungslogik:} Der lineare Datenfluss und die klare Verantwortungstrennung der Filter vereinfachen das Verständnis der Geschäftslogik und das Debugging im Vergleich zu stark vernetzten Architekturen.\cite{richards2020}
\item \textbf{Modularität und Wiederverwendbarkeit:} Filter als "Blackboxes" mit definierten Verträgen ermöglichen Austausch und Wiederverwendung, was Entwicklungs- und Wartungskosten senkt.\cite{packt_cpp_architecture}
\item \textbf{Flexibilität und Parallelisierbarkeit:} Die Entkopplung durch Pipes (insbesondere Message Queues) ermöglicht eine natürliche Parallelisierung, da mehrere Instanzen eines Filters konkurrierend Nachrichten verarbeiten können, was die Skalierbarkeit fördert.\cite{researchgate_parallel_pipes}
\end{itemize}

\subsection{Herausforderungen und der Kompromiss der Komplexität}
Die scheinbare Einfachheit des Pipeline-Stils birgt versteckte Komplexitäten. Gemäß dem Grundsatz der "Erhaltung der Komplexität" (Conservation of Complexity) verschwindet diese nicht, sondern verlagert sich lediglich – typischerweise von der Anwendungslogik in die Infrastruktur und den Betrieb. Die Entscheidung für eine Pipeline-Architektur, insbesondere in verteilter Form, ist daher ein bewusster Tausch.

\textbf{Traditionelle, monolithische Implementierungen} leiden unter geringer Skalierbarkeit und Fehlertoleranz, da das gesamte System als eine Einheit skaliert und ein Fehler in einem Filter die ganze Kette lahmlegen kann.\cite{richards2020}

\textbf{Moderne, verteilte Implementierungen} (z.B. mit Microservices) lösen diese Probleme, führen aber neue, gravierende Herausforderungen ein:
\begin{itemize}
\item \textbf{Massiv erhöhte operationelle Komplexität:} Die einfache Anwendungslogik wird mit dem Aufwand für Deployment, Konfiguration, Service Discovery und verteiltes Monitoring "erkauft". Dies erfordert spezialisierte Werkzeuge (z.B. Kubernetes) und tiefes Know-how.\cite{richards2020}
Cloud-Plattformen wie Microsoft Azure bieten hierfür dedizierte, verwaltete Dienste (z.B. Azure Functions als Filter und Azure Service Bus als Pipe), welche die Implementierung erleichtern, die zugrundeliegende Komplexität aber nicht vollständig eliminieren.\cite{azure_pipes_filters}

\item \textbf{Fehlerbehandlung und Resilienz:} Dieser Aspekt wird oft vernachlässigt. Was passiert, wenn ein Filter in der Mitte der Kette ausfällt? Eine End-to-End-Transaktionalität existiert typischerweise nicht. Robuste Systeme erfordern daher explizite Resilienz-Muster:
    \begin{itemize}
        \item \textbf{Dead Letter Queues (DLQ):} Um Nachrichten, die wiederholt nicht verarbeitet werden können, zur Analyse auszulagern und die Pipeline nicht zu blockieren.
        \item \textbf{Wiederholungsmechanismen (Retries):} Temporäre Fehler (z.B. Netzwerkprobleme) müssen durch Retries (oft mit exponentiellem Backoff) abgefangen werden.
        \item \textbf{Idempotenz:} Filter müssen so gestaltet sein, dass eine mehrfache Verarbeitung derselben Nachricht (z.B. nach einem Retry) nicht zu Datenkorruption führt.
    \end{itemize}
\item \textbf{Latenz vs. Durchsatz:} Der Stil ist auf hohen \textbf{Durchsatz} (Throughput) optimiert, nicht auf geringe \textbf{Latenz} (Latency). Die End-to-End-Latenz ist die Summe aller Verarbeitungs- und Netzwerklatenzen zwischen den Filtern. Dies macht den Stil für interaktive Echtzeitanwendungen, die sofortiges Feedback erfordern, ungeeignet.\cite{uqcloud_pipeline}
\item \textbf{Observability und Datenkonsistenz:} Das Nachverfolgen von Datenflüssen über asynchrone Dienste hinweg erfordert verteiltes Tracing und zentrale Log-Aggregation. Die Gewährleistung von Datenkonsistenz (z.B. Exactly-Once-Semantik) über verteilte Pipes hinweg ist eine nichttriviale Herausforderung.\cite{richards2020}
\end{itemize}

% --- SCHAUBILD 3: VERGLEICH MONOLITH vs. VERTEILT ---
\begin{figure}[h!]
\centering
% Teil A: Monolithische Pipeline
\begin{tikzpicture}
\node (f1) [filter_node, text width=1.8cm] {Filter A};
\node (f2) [filter_node, text width=1.8cm, right=2.2cm of f1] {Filter B};
\node (f3) [filter_node, text width=1.8cm, right=2.2cm of f2] {Filter C};
\node (title_a) [above=0.5cm of f2] {\textbf{A) Monolithische Pipeline}};

\begin{pgfonlayer}{background}
        \node (background) [fit=(f1)(f3)(title_a), draw, rounded corners, fill=gray!20, inner sep=10pt] {};
        \node [above=1pt of background, font=\small] {Ein Applikationsprozess};
\end{pgfonlayer}
    
\draw [pipe_arrow, dashed] (f1) -- node[above, pipe_label] {In-Memory} (f2);
\draw [pipe_arrow, dashed] (f2) -- node[above, pipe_label] {Methodenaufruf} (f3);
\end{tikzpicture}

\vspace{1.2cm}

% Teil B: Verteilte Pipeline
\begin{tikzpicture}
    \node (s1) [filter_node, fill=green!30, text width=2.2cm] {Service A (Filter)};
    \node (broker) [broker_node, right=2cm of s1, text width=1.8cm] {Message Broker};
    \node (s2) [filter_node, fill=green!30, text width=2.2cm, right=2cm of broker] {Service B (Filter)};
    \node (title_b) [above=0.5cm of broker] {\textbf{B) Verteilte Pipeline}};
    
    \draw [pipe_arrow] (s1) -- node[above, pipe_label] {Netzwerk} (broker);
    \draw [pipe_arrow] (broker) -- node[above, pipe_label] {Netzwerk} (s2);
\end{tikzpicture}

\caption{Vergleich einer monolithischen Implementierung (A), bei der alle Filter im selben Prozess laufen, mit einer verteilten Implementierung (B), bei der unabhängige Dienste über einen robusten Message Broker (Pipe) via Netzwerk kommunizieren.}
\label{fig:monolith_vs_distributed}
\end{figure}

\section{Schlussfolgerung}
Der Pipeline-Architekturstil bleibt ein wertvolles Muster, dessen Stärke in der Modularisierung komplexer Aufgaben in sequenzielle, unabhängige Verarbeitungsschritte liegt. Die Prinzipien der klaren Verantwortungstrennung und des linearen Datenflusses fördern die Verständlichkeit der Anwendungslogik.

Die kritische Analyse zeigt jedoch, dass diese Einfachheit oft mit einer signifikanten Verlagerung der Komplexität in den Betrieb und die Infrastruktur erkauft wird. Während monolithische Implementierungen an Skalierbarkeits- und Robustheitsgrenzen stoßen, lösen moderne, verteilte Ansätze diese Probleme, führen aber neue Herausforderungen in den Bereichen operationelle Komplexität, Resilienz und Latenz ein. Die Notwendigkeit von Idempotenz, Fehlerbehandlungsstrategien wie Dead Letter Queues und dem Management von Datenverträgen wird in solchen Systemen überlebenswichtig.

Die Effektivität des Pipeline-Stils ist somit weniger eine Frage des Musters selbst, sondern der bewussten architektonischen Entscheidung für einen Kompromiss: Er ist ideal für Systeme, die auf hohen Durchsatz und nicht auf niedrige Latenz optimiert sind und bei denen die Vorteile der modularen, unabhängigen Skalierung die Nachteile der erhöhten Betriebskomplexität überwiegen.

\newpage
\begin{thebibliography}{99}
\bibitem{richards2020} Mark Richards und Neal Ford. \textit{Handbuch Moderner Softwarearchitektur: Architekturstile, Patterns und Best Practices}. O'Reilly Verlag GmbH & Co. KG, 2020.
\bibitem{uqcloud_pipeline} CSSE6400. \textit{Pipeline Architecture}. \url{https://csse6400.uqcloud.net/handouts/pipeline.pdf}
\bibitem{oreilly_python_pipes} O'Reilly. \textit{Software Architecture with Python: Pipe and Filter architectures}. \url{https://www.oreilly.com/library/view/software-architecture-with/9781786468529/ch08s04.html}
\bibitem{researchgate_parallel_pipes} ResearchGate. \textit{The Pipes and Filters Pattern: A Functional Parallelism Architectural Pattern for Parallel Programming}. \url{https://www.researchgate.net/publication/221034471_The_Pipes_and_Filters_Pattern_A_Functional_Parallelism_Architectural_Pattern_for_Parallel_Programming}
\bibitem{azure_pipes_filters} Explore Azure Cloud. \textit{Pipes and Filters Pattern in Azure - Part 1}. \url{https://exploreazurecloud.com/pipes-and-filters-pattern-in-azure-part-1}
\bibitem{projectpro_etl_usecases} ProjectPro. \textit{Top ETL Use Cases for BI and Analytics: Real-World Examples}. \url{https://www.projectpro.io/article/etl-use-cases/768}
\bibitem{researchgate_etl_dist} ResearchGate. \textit{Distributed ETL Architecture for Processing and Storing Bigdata}. \url{https://www.researchgate.net/publication/382522030_Distributed_ETL_Architecture_for_Processing_and_Storing_Bigdata}
\bibitem{wso2_eip} WSO2 Docs. \textit{Pipes and Filters EIP}. \url{https://wso2docs.atlassian.net/wiki/spaces/EIP/pages/48791632/Pipes+and+Filters}
\bibitem{acceldata_streaming} Acceldata. \textit{Mastering Streaming Data Pipelines for Real-Time Data Processing}. \url{https://www.acceldata.io/blog/mastering-streaming-data-pipelines-for-real-time-data-processing}
\bibitem{dagster_frameworks} Dagster. \textit{Data Pipeline Frameworks: Key Features & 10 Tools to Know in 2024}. \url{https://dagster.io/guides/data-pipeline/data-pipeline-frameworks-key-features-10-tools-to-know-in-2024}
\bibitem{packt_cpp_architecture} Packt. \textit{Software Architecture with C++: Architectural and System Design}. \url{https://www.packtpub.com/fr-cy/product/software-architecture-with-c-9781838554590/chapter/architectural-and-system-design-6/section/pipes-and-filters-pattern-ch06lvl1sec35}
\bibitem{dagster_data_pipeline} Dagster. \textit{Data Pipeline}. \url{https://dagster.io/guides/data-pipeline}
\end{thebibliography}

\end{document}
